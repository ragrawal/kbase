# Sum of Squared Error (SSE)
$$SSE = \sum_{i}(y_i - \hat{y_i})^2$$

* By taking square, we weight points that are predicted farther from it's origianl value.
* SSE is used as an optimization function in [[Regression#Ordinary Least Square Regression| OLS]] for two reasons:
	* Square makes the above function differentiable. 
	* Taking square makes error additive. Alternatively we could have used absolute function but then it's not continuously differentiable. 

# Mean Absolute Error (MAE)

# R-Square

# Adjusted R-Square
